overall task
- LoRA fine tune search-r1 on FinQA dataset, with answer reward, using verl
currently have
- verl training framework for search-r1
need to modify
- dataset
- search engine
- training parameter(LoRA)

More details
- reward
- LoRA checking 
- update script based on verl/examples/tuning

"Error executing job with overrides: ['data.train_files=data/finqa_combined/train.parquet', 'data.val_files=data/finqa_combined/validation.parquet', 'data.train_data_num=null', 'data.val_data_num=null', 'data.train_batch_size=16', 'data.val_batch_size=8', 'data.max_prompt_length=4096', 'data.max_response_length=500', 'data.max_start_length=2048', 'data.max_obs_length=500', 'data.shuffle_train_dataloader=True', 'algorithm.adv_estimator=gae', 'actor_rollout_ref.model.path=PeterJinGo/SearchR1-nq_hotpotqa_train-qwen2.5-3b-em-ppo-v0.3', 'actor_rollout_ref.model.enable_gradient_checkpointing=true', 'actor_rollout_ref.model.use_remove_padding=True', '+actor_rollout_ref.model.lora_rank=8', '+actor_rollout_ref.model.lora_alpha=16', '+actor_rollout_ref.model.target_modules=[k_proj,v_proj]', 'actor_rollout_ref.actor.optim.lr=1e-6', 'actor_rollout_ref.actor.optim.lr_warmup_steps_ratio=0.285', 'actor_rollout_ref.actor.ppo_mini_batch_size=8', 'actor_rollout_ref.actor.ppo_micro_batch_size=4', 'actor_rollout_ref.actor.fsdp_config.param_offload=false', 'actor_rollout_ref.actor.fsdp_config.grad_offload=false', 'actor_rollout_ref.actor.fsdp_config.optimizer_offload=false', 'actor_rollout_ref.rollout.log_prob_micro_batch_size=8', 'actor_rollout_ref.rollout.tensor_model_parallel_size=1', 'actor_rollout_ref.rollout.name=vllm', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.9', 'actor_rollout_ref.ref.log_prob_micro_batch_size=8', 'actor_rollout_ref.ref.fsdp_config.param_offload=false', 'actor_rollout_ref.rollout.n_agent=1', 'actor_rollout_ref.rollout.temperature=1', 'actor_rollout_ref.actor.state_masking=true', 'critic.optim.lr=1e-5', 'critic.model.use_remove_padding=True', 'critic.optim.lr_warmup_steps_ratio=0.015', 'critic.model.path=PeterJinGo/SearchR1-nq_hotpotqa_train-qwen2.5-3b-em-ppo-v0.3', 'critic.model.enable_gradient_checkpointing=true', 'critic.ppo_micro_batch_size=4', 'critic.model.fsdp_config.param_offload=false', 'critic.model.fsdp_config.grad_offload=false', 'critic.model.fsdp_config.optimizer_offload=false', 'algorithm.kl_ctrl.kl_coef=0.001', 'algorithm.no_think_rl=false', 'trainer.critic_warmup=0', 'trainer.logger=[wandb]', '+trainer.val_only=false', '+trainer.val_before_train=true', 'trainer.default_hdfs_dir=null', 'trainer.n_gpus_per_node=1', 'trainer.nnodes=1', 'trainer.save_freq=10', 'trainer.test_freq=10', 'trainer.project_name=Search-R1-Finetune-LoRA', 'trainer.experiment_name=my-custom-task-ppo-llama3.2-3b-fin-lora', 'trainer.total_epochs=15', 'trainer.total_training_steps=1005', 'trainer.default_hdfs_dir=null', 'trainer.default_local_dir=verl_checkpoints/my-custom-task-ppo-llama3.2-3b-fin-lora', 'max_turns=2', 'do_search=true', 'retriever.topk=3']
Traceback (most recent call last):
  File "/content/RL_lab/search-r1-fin/Search-R1/verl/trainer/main_ppo.py", line 110, in main
    ray.get(main_task.remote(config))
  File "/usr/local/lib/python3.11/dist-packages/ray/_private/auto_init_hook.py", line 22, in auto_init_wrapper
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/ray/_private/client_mode_hook.py", line 104, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py", line 2849, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/dist-packages/ray/_private/worker.py", line 937, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(UnboundLocalError): ray::main_task() (pid=4732, ip=172.28.0.12)
  File "/content/RL_lab/search-r1-fin/Search-R1/verl/trainer/main_ppo.py", line 198, in main_task
    trainer.fit()
  File "/content/RL_lab/search-r1-fin/Search-R1/verl/trainer/ppo/ray_trainer.py", line 667, in fit
    val_metrics = self._validate()
                  ^^^^^^^^^^^^^^^^
  File "/content/RL_lab/search-r1-fin/Search-R1/verl/trainer/ppo/ray_trainer.py", line 463, in _validate
    indexers=batch_dict['indexers'] if 'indexers' in batch_dict else None,
                                                     ^^^^^^^^^^
UnboundLocalError: cannot access local variable 'batch_dict' where it is not associated with a value"